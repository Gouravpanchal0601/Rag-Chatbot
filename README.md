# ğŸ“˜ RAG ChatBot

A Retrieval-Augmented Generation (RAG) chatbot that allows users to
upload PDF documents and ask context-aware questions. It
extracts relevant information from the documents and generates accurate,
conversational, and grounded responses. The system combines document
retrieval with LLM reasoning, ensuring reliable answers backed by
the uploaded content.

------------------------------------------------------------------------

## ğŸš€ Features

-   ğŸ“„ Upload PDF files (up to 200MB)
-   ğŸ” Intelligent text extraction & chunking
-   ğŸ¤– Context-aware question answering using RAG
-   âš¡ Fast, accurate retrieval from vector database
-   ğŸ’¬ Chat interface for smooth conversational experience
-   ğŸ§  Reduces hallucinations by grounding answers in the document

------------------------------------------------------------------------

## ğŸ› ï¸ Tech Stack

-   **Python**
-   **Streamlit** -- UI
-   **LangChain / LlamaIndex** -- RAG pipeline
-   **FAISS / ChromaDB** -- Vector database
-   **OpenAI / HuggingFace Embeddings**

------------------------------------------------------------------------

## ğŸ“ Project Structure

    ğŸ“¦ rag-chatbot
    â”œâ”€â”€ app.py               # Streamlit UI
    â”œâ”€â”€ rag_pipeline.py      # RAG logic (embeddings, retrieval, generation)
    â”œâ”€â”€ utils.py             # Helper functions
    â”œâ”€â”€ requirements.txt     # Dependencies
    â”œâ”€â”€ README.md            # Project documentation
    â””â”€â”€ assets/              # Images, icons, etc.

------------------------------------------------------------------------

## ğŸ§  How It Works

1.  User uploads a PDF.
2.  Text is extracted and split into chunks.
3.  Chunks are converted into vector embeddings.
4.  Embedded vectors are stored in a vector database.
5.  User asks a question.
6.  System retrieves the most relevant chunks.
7.  LLM generates a grounded answer using retrieved context.

This ensures reliable, factual, and document-based responses.

------------------------------------------------------------------------

## â–¶ï¸ Getting Started

### 1ï¸âƒ£ Install Dependencies

``` bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run the Application

``` bash
streamlit run app.py
```

### 3ï¸âƒ£ Open in Browser

    http://localhost:8501

------------------------------------------------------------------------

## ğŸ“¤ How to Use

1.  Launch the app.
2.  Upload a PDF using the file uploader.
3.  Wait for processing.
4.  Start chatting and ask document-related questions.

------------------------------------------------------------------------

## ğŸ“¸ Screenshots

*Add UI screenshots here.*

------------------------------------------------------------------------

## ğŸ§© Future Enhancements

-   Multi-PDF conversation support
-   Embedding caching for faster reloads
-   Chat export feature
-   Model selection option

------------------------------------------------------------------------

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues or submit pull
requests.

------------------------------------------------------------------------

## ğŸ“œ License

This project is licensed under the **MIT License**.

------------------------------------------------------------------------
